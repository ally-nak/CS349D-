{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: An OpenAI API key must be set here for application initialization, even if not in use.\n",
    "# If you're not utilizing OpenAI models, assign a placeholder string (e.g., \"not_used\").\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ally_Mac/CS349D/raptor/raptor/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "import sacrebleu\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 17:16:25,152 - Loading faiss.\n",
      "2024-06-12 17:16:25,177 - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from raptor import RetrievalAugmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"deepmind/narrativeqa\", split=\"test[:1000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sorted(dataset, key=lambda x: x['document']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_preserve_sentences(text, ratio=0.8):\n",
    "    sentences = sent_tokenize(text)\n",
    "    split_idx = int(len(sentences) * ratio)\n",
    "    return ' '.join(sentences[:split_idx]), ' '.join(sentences[split_idx:])\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge_scores(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {key: [] for key in ['rouge1', 'rouge2', 'rougeL']}\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        for key in scores:\n",
    "            rouge_scores[key].append(scores[key].fmeasure)\n",
    "    return {key: np.mean(values) for key, values in rouge_scores.items()}\n",
    "\n",
    "# Function to calculate BLEU scores\n",
    "def calculate_bleu_scores(predictions, references):\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Calculate BLEU-1\n",
    "        bleu1 = sacrebleu.corpus_bleu([pred], [[ref]], smooth_method='exp', smooth_value=0.0, use_effective_order=False).precisions[0]\n",
    "        bleu1_scores.append(bleu1)\n",
    "        \n",
    "        # Calculate BLEU-4\n",
    "        bleu4 = sacrebleu.corpus_bleu([pred], [[ref]], smooth_method='exp', smooth_value=0.0, use_effective_order=False).score\n",
    "        bleu4_scores.append(bleu4)\n",
    "    \n",
    "    # Return the average BLEU-1 and BLEU-4 scores\n",
    "    return {\n",
    "        \"bleu1\": np.mean(bleu1_scores),\n",
    "        \"bleu4\": np.mean(bleu4_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {}\n",
    "\n",
    "# Placeholder for all QA results\n",
    "all_full_rouge_scores = []\n",
    "all_full_bleu1_scores = []\n",
    "all_full_bleu4_scores = []\n",
    "all_partial_rouge_scores = []\n",
    "all_partial_bleu1_scores = []\n",
    "all_partial_bleu4_scores = []\n",
    "\n",
    "time_diff = []\n",
    "magnitude_diff = []\n",
    "\n",
    "# Placeholder to avoid rebuilding trees\n",
    "full_trees = {}\n",
    "partial_trees = {}\n",
    "\n",
    "# Main processing\n",
    "for i, row in enumerate(dataset):\n",
    "    print(\"Processing ROW : \", i)\n",
    "    doc_id = row[\"document\"][\"id\"]\n",
    "    text = row[\"document\"][\"summary\"][\"text\"]\n",
    "    question = row[\"question\"][\"text\"]\n",
    "    answers = [ans[\"text\"] for ans in row[\"answers\"]]\n",
    "\n",
    "    # Split the text into 4/5 and 1/5 while preserving full sentences\n",
    "    text_4_5, text_1_5 = split_text_preserve_sentences(text, ratio=0.8)\n",
    "\n",
    "    # Build tree and evaluate for full text if not already built\n",
    "    if doc_id not in full_trees:\n",
    "        # Full text tree\n",
    "        start_time = time.time()\n",
    "        RA = RetrievalAugmentation() \n",
    "        RA.add_documents(text) \n",
    "        full_build_time = time.time() - start_time\n",
    "        # Store tree\n",
    "        full_trees[doc_id] = RA\n",
    "\n",
    "        # Build tree for 4/5 text and add 1/5 text\n",
    "        PartialTree = RetrievalAugmentation() \n",
    "        PartialTree.add_documents(text_4_5) \n",
    "\n",
    "        # Adding 1/5 text\n",
    "        start_time = time.time()\n",
    "        PartialTree.add_to_existing(text_1_5)\n",
    "        add_1_5_time = time.time() - start_time\n",
    "\n",
    "        # Store tree\n",
    "        partial_trees[doc_id] = PartialTree\n",
    "\n",
    "        # Record Times:\n",
    "        times[doc_id] = {\n",
    "            \"full_build_time\": full_build_time,\n",
    "            \"add_1_5_time\": add_1_5_time,\n",
    "            \"difference\": full_build_time - add_1_5_time,\n",
    "            \"multiplier\": full_build_time / add_1_5_time\n",
    "        }\n",
    "        time_diff.append(full_build_time - add_1_5_time)\n",
    "        magnitude_diff.append(full_build_time / add_1_5_time)\n",
    "\n",
    "    RA = full_trees[doc_id]\n",
    "    # Evaluate QA on full text tree\n",
    "    full_predictions = [RA.answer_question(question=question)]\n",
    "    # print(\"question \", question)\n",
    "    # print(\"ouput\", full_predictions)\n",
    "\n",
    "    full_rouge_scores = calculate_rouge_scores(full_predictions, answers)\n",
    "    full_bleu_score = calculate_bleu_scores(full_predictions, answers)\n",
    "    # Save scores for averaging\n",
    "    all_full_rouge_scores.append(full_rouge_scores)\n",
    "    all_full_bleu1_scores.append(full_bleu_score[\"bleu1\"])\n",
    "    all_full_bleu4_scores.append(full_bleu_score[\"bleu4\"])\n",
    "\n",
    "    PartialTree = partial_trees[doc_id]\n",
    "    # Evaluate QA on partial text tree\n",
    "    partial_predictions = [PartialTree.answer_question(question)]\n",
    "    # print(\"expeirmental ouput\", full_predictions)\n",
    "    \n",
    "    partial_rouge_scores = calculate_rouge_scores(partial_predictions, answers)\n",
    "    partial_bleu_score = calculate_bleu_scores(partial_predictions, answers)\n",
    "    # print(\"right answer\", answers)\n",
    "\n",
    "    # Save scores for averaging\n",
    "    all_partial_rouge_scores.append(partial_rouge_scores)\n",
    "    all_partial_bleu1_scores.append(partial_bleu_score[\"bleu1\"])\n",
    "    all_partial_bleu4_scores.append(partial_bleu_score[\"bleu4\"])\n",
    "\n",
    "# Calculate average scores\n",
    "average_full_rouge_scores = {key: np.mean([score[key] for score in all_full_rouge_scores]) for key in all_full_rouge_scores[0]}\n",
    "average_full_bleu1_score = np.mean(all_full_bleu1_scores)\n",
    "average_full_bleu4_score = np.mean(all_full_bleu4_scores)\n",
    "average_partial_rouge_scores = {key: np.mean([score[key] for score in all_partial_rouge_scores]) for key in all_partial_rouge_scores[0]}\n",
    "average_partial_bleu1_score = np.mean(all_partial_bleu1_scores)\n",
    "average_partial_bleu4_score = np.mean(all_partial_bleu4_scores)\n",
    "\n",
    "\n",
    "# Output results\n",
    "print(\"Average Full Tree ROUGE Scores:\", average_full_rouge_scores)\n",
    "print(\"Average Full Tree BLEU1 Score:\", average_full_bleu1_score)\n",
    "print(\"Average Full Tree BLEU4 Score:\", average_full_bleu4_score)\n",
    "print(\"Average Partial Tree ROUGE Scores:\", average_partial_rouge_scores)\n",
    "print(\"Average Partial Tree BLEU1 Score:\", average_partial_bleu1_score)\n",
    "print(\"Average Partial Tree BLEU4 Score:\", average_partial_bleu4_score)\n",
    "print(\"Average Time Difference:\", np.mean(time_diff))\n",
    "print(\"Average Magnitude Difference:\", np.mean(magnitude_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick output test \n",
    "print(\"Average Full Tree ROUGE Scores:\", average_full_rouge_scores)\n",
    "print(\"Average Full Tree BLEU1 Score:\", average_full_bleu1_score)\n",
    "print(\"Average Full Tree BLEU4 Score:\", average_full_bleu4_score)\n",
    "print(\"Average Partial Tree ROUGE Scores:\", average_partial_rouge_scores)\n",
    "print(\"Average Partial Tree BLEU1 Score:\", average_partial_bleu1_score)\n",
    "print(\"Average Partial Tree BLEU4 Score:\", average_partial_bleu4_score)\n",
    "print(\"Average Time Difference:\", np.mean(time_diff))\n",
    "print(\"Average Magnitude Difference:\", np.mean(magnitude_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
